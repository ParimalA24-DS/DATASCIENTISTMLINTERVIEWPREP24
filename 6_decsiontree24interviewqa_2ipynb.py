# -*- coding: utf-8 -*-
"""6.DECSIONTREE24INTERVIEWQA.2ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pwHp-YLifIBDztHUCVSjneeZ9zm99c8r

# **6.DECISON TREE:**
- Data scientist Interview preparation
- Practical
- June2024
- II.Decison Tree Regressor

## **Supervised ml :classifcation & regression task**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

##Boston House Pricing Dataset :sklearn # dont run this cell
from sklearn.datasets import load_boston
boston_df=load_boston()
#Note: The Boston housing dataset has been deprecated in scikit-learn due to
#ethical concerns and is no longer available in the latest version

from sklearn.datasets import fetch_openml

# Load the Boston housing dataset from OpenML
boston = fetch_openml(data_id=531)

boston

print(boston.feature_names)

print(boston.data.shape)
print(boston.target.shape)

# Extract features and target
X = boston.data
y = boston.target

X

y

#or you canwrite #independent features
X=pd.DataFrame(boston_df.data,columns=boston_df.feature_names)
#dependent features
y=boston_df.target

### train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
     X, y, test_size=0.20, random_state=42)

"""## **II.DECISION TREE REGRESSOR:**
- Post pruning
- Pre pruning
"""

from sklearn.tree import DecisionTreeRegressor
regressor=DecisionTreeRegressor()
regressor.fit(X_train,y_train)

from sklearn.tree import plot_tree
plt.figure(figsize=(15, 13))
plot_tree(regressor, filled=True, feature_names=boston.feature_names)
plt.title("Decision Tree Regressor - Boston Housing Dataset")
plt.show()

regressor.fit(X_train,y_train)

y_pred=regressor.predict(X_test)

from sklearn.metrics import r2_score
score=r2_score(y_pred,y_test)

score

# Hyperparameter Tunning
parameter={
 'criterion':['squared_error','friedman_mse','absolute_error','poisson'],
  'splitter':['best','random'],
  'max_depth':[1,2,3,4,5,6,7,8,10,11,12],
  'max_features':['auto', 'sqrt', 'log2']

}

regressor=DecisionTreeRegressor()

from sklearn.model_selection import GridSearchCV
regressorcv=GridSearchCV(regressor,param_grid=parameter,cv=5,scoring='neg_mean_squared_error')

import warnings
warnings.filterwarnings('ignore')

regressorcv.fit(X_train,y_train)

regressorcv.best_params_

y_pred=regressorcv.predict(X_test)

r2_score(y_pred,y_test)

"""**Post pruning**
- post pruning :cutting down the specific nodes after building the Decision Tree
"""

#post pruning :cutting down the specific nodes after building the Decision Tree

"""**II.Pre pruning:**
- It is used before the construction of decision tree wih hyperparameter tuning and crsoss validation

- - criterion: Determines how the quality of a split is measured.
- - splitter: Determines the strategy used to choose the split at each node.
- - max_depth: Limits the depth of the tree to prevent it from becoming too complex and overfitting the data.
- - max_features: Limits the number of features considered for splitting at each node, which can reduce overfitting and improve computational efficiency.
"""

#Save: Normal DT Regressor:1
import joblib

# Save the model
joblib.dump(regressor, 'model_DT2.pkl')

# Load the model
model = joblib.load('model_DT2.pkl')

#DT2 MODEL SAVE

